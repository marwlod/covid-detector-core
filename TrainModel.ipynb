{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./venv/lib/python3.6/site-packages (4.5.2.54)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in ./venv/lib/python3.6/site-packages (from opencv-python) (1.19.5)\r\n",
      "Requirement already satisfied: ttach in ./venv/lib/python3.6/site-packages (0.0.3)\r\n",
      "Requirement already satisfied: grad-cam in ./venv/lib/python3.6/site-packages (1.2.9)\r\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "!pip install opencv-python\n",
    "!pip install ttach\n",
    "!pip install grad-cam\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Configurate hyperparameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DetectorDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dirs, transform):\n",
    "        self.images = {}\n",
    "        # normal class will be displayed as 0 in results, viral as 1, covid as 2\n",
    "        self.classes = ['normal', 'viral', 'covid']\n",
    "        for c in self.classes:\n",
    "            self.images[c] = [x for x in os.listdir(dirs[c]) if x[-3:].lower().endswith('png')]\n",
    "        self.image_dirs = dirs\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum([len(self.images[c]) for c in self.classes])\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # TODO implement Weighted Random Sampling\n",
    "        c = random.choice(self.classes)\n",
    "        i = i % len(self.images[c])\n",
    "        image_name = self.images[c][i]\n",
    "        image_path = os.path.join(self.image_dirs[c], image_name)\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        return self.transform(image), self.classes.index(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "means = [0.485, 0.456, 0.406]\n",
    "stds = [0.229, 0.224, 0.225]\n",
    "image_size = (224, 224)\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=image_size),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=means, std=stds)\n",
    "])\n",
    "train_dirs = {\n",
    "    'normal': 'COVID-19_Radiography_Dataset/normal',\n",
    "    'viral': 'COVID-19_Radiography_Dataset/viral',\n",
    "    'covid': 'COVID-19_Radiography_Dataset/covid'\n",
    "}\n",
    "train_dataset = DetectorDataset(train_dirs, train_transform)\n",
    "dl_train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=image_size),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=means, std=stds)\n",
    "])\n",
    "test_dirs = {\n",
    "    'normal': 'COVID-19_Radiography_Dataset/test/normal',\n",
    "    'viral': 'COVID-19_Radiography_Dataset/test/viral',\n",
    "    'covid': 'COVID-19_Radiography_Dataset/test/covid'\n",
    "}\n",
    "test_dataset = DetectorDataset(test_dirs, test_transform)\n",
    "dl_test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(in_features=2048, out_features=3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Enable GPU acceleration on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix'):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    thresh = 2 * cm.max()\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "validate_every = 200\n",
    "\n",
    "def evaluate_model(show_plots=False):\n",
    "    model.eval()\n",
    "    pred_list, true_list = [], []\n",
    "    accuracy, test_loss = 0, 0\n",
    "\n",
    "    for images, labels in dl_test:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        accuracy += sum((predictions == labels)).to(device)\n",
    "        if show_plots:\n",
    "            pred_list += list(predictions.cpu().numpy())\n",
    "            true_list += list(labels.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(dl_test)\n",
    "    accuracy = accuracy / len(test_dataset)\n",
    "    if show_plots:\n",
    "        print(classification_report(pred_list, true_list, digits=5))\n",
    "        cm = confusion_matrix(true_list, pred_list)\n",
    "        plot_confusion_matrix(cm = cm, target_names = ['normal', 'viral', 'covid'])\n",
    "    model.train()\n",
    "    return test_loss, accuracy\n",
    "\n",
    "def train_model(epochs=10):\n",
    "    train_losses, test_losses = [], []\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    best_loss = np.inf\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Starting epoch\", epoch + 1, \"/\", epochs)\n",
    "        train_loss, train_step = 0, 0\n",
    "        model.train()\n",
    "        for images, labels in dl_train:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels).to(device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            if train_step % validate_every == 0:\n",
    "                test_loss, accuracy = evaluate_model()\n",
    "                print(\"Validation loss:\", test_loss, \", accuracy:\", accuracy.item(),\n",
    "                      \"at step\", train_step)\n",
    "            train_step += 1\n",
    "        # at the end of each epoch check if the model is getting better\n",
    "        test_loss, accuracy = evaluate_model()\n",
    "        if test_loss < best_loss:\n",
    "            print(\"Saving new best model with validation loss\", test_loss,\n",
    "                  \"and accuracy\", accuracy.item())\n",
    "            best_loss = test_loss\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "        train_loss /= len(dl_train)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(\"Training loss after epoch\", epoch + 1, \":\", train_loss)\n",
    "    print(\"Training done\")\n",
    "    model.load_state_dict(best_weights)\n",
    "    plt.plot(train_losses, label=\"Training loss\")\n",
    "    plt.plot(test_losses, label=\"Validation loss\")\n",
    "    plt.legend(frameon=False)\n",
    "    plt.show()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training..\n",
      "====================\n",
      "Starting epoch 1/5\n",
      "====================\n",
      "Evaluating at step 0\n",
      "Validation Loss: 1.0892, Accuracy: 0.3983\n",
      "Evaluating at step 20\n",
      "Validation Loss: 0.6125, Accuracy: 0.7617\n",
      "Evaluating at step 40\n",
      "Validation Loss: 0.3581, Accuracy: 0.8733\n",
      "Evaluating at step 60\n",
      "Validation Loss: 0.2583, Accuracy: 0.8933\n",
      "Evaluating at step 80\n",
      "Validation Loss: 0.2058, Accuracy: 0.9217\n",
      "Evaluating at step 100\n",
      "Validation Loss: 0.1815, Accuracy: 0.9367\n",
      "Evaluating at step 120\n",
      "Validation Loss: 0.1718, Accuracy: 0.9433\n",
      "Evaluating at step 140\n",
      "Validation Loss: 0.1534, Accuracy: 0.9400\n",
      "Evaluating at step 160\n",
      "Validation Loss: 0.1506, Accuracy: 0.9350\n",
      "Evaluating at step 180\n",
      "Validation Loss: 0.1209, Accuracy: 0.9533\n",
      "Evaluating at step 200\n",
      "Validation Loss: 0.1226, Accuracy: 0.9633\n",
      "Evaluating at step 220\n",
      "Validation Loss: 0.1111, Accuracy: 0.9650\n",
      "Evaluating at step 240\n",
      "Validation Loss: 0.1029, Accuracy: 0.9783\n",
      "Evaluating at step 260\n",
      "Validation Loss: 0.0891, Accuracy: 0.9750\n",
      "Evaluating at step 280\n",
      "Validation Loss: 0.0825, Accuracy: 0.9750\n",
      "Evaluating at step 300\n",
      "Validation Loss: 0.0737, Accuracy: 0.9817\n",
      "Evaluating at step 320\n",
      "Validation Loss: 0.0742, Accuracy: 0.9767\n",
      "Evaluating at step 340\n",
      "Validation Loss: 0.1031, Accuracy: 0.9650\n",
      "Evaluating at step 360\n",
      "Validation Loss: 0.0779, Accuracy: 0.9717\n",
      "Evaluating at step 380\n",
      "Validation Loss: 0.0741, Accuracy: 0.9750\n",
      "Evaluating at step 400\n",
      "Validation Loss: 0.0622, Accuracy: 0.9817\n",
      "Evaluating at step 420\n",
      "Validation Loss: 0.0845, Accuracy: 0.9750\n",
      "Evaluating at step 440\n",
      "Validation Loss: 0.1057, Accuracy: 0.9500\n",
      "Evaluating at step 460\n",
      "Validation Loss: 0.0733, Accuracy: 0.9650\n",
      "Evaluating at step 480\n",
      "Validation Loss: 0.1211, Accuracy: 0.9500\n",
      "Evaluating at step 500\n",
      "Validation Loss: 0.0762, Accuracy: 0.9800\n",
      "Evaluating at step 520\n",
      "Validation Loss: 0.0814, Accuracy: 0.9800\n",
      "Evaluating at step 540\n",
      "Validation Loss: 0.0914, Accuracy: 0.9567\n",
      "Evaluating at step 560\n",
      "Validation Loss: 0.0801, Accuracy: 0.9733\n",
      "Evaluating at step 580\n",
      "Validation Loss: 0.0780, Accuracy: 0.9683\n",
      "Evaluating at step 600\n",
      "Validation Loss: 0.0756, Accuracy: 0.9750\n",
      "Evaluating at step 620\n",
      "Validation Loss: 0.0488, Accuracy: 0.9850\n",
      "Evaluating at step 640\n",
      "Validation Loss: 0.0664, Accuracy: 0.9767\n",
      "Evaluating at step 660\n",
      "Validation Loss: 0.0548, Accuracy: 0.9817\n",
      "Evaluating at step 680\n",
      "Validation Loss: 0.0891, Accuracy: 0.9633\n",
      "Evaluating at step 700\n",
      "Validation Loss: 0.0913, Accuracy: 0.9617\n",
      "Evaluating at step 720\n",
      "Validation Loss: 0.0588, Accuracy: 0.9783\n",
      "Evaluating at step 740\n",
      "Validation Loss: 0.0885, Accuracy: 0.9567\n",
      "Evaluating at step 760\n",
      "Validation Loss: 0.0586, Accuracy: 0.9733\n",
      "Evaluating at step 780\n",
      "Validation Loss: 0.0522, Accuracy: 0.9867\n",
      "Evaluating at step 800\n",
      "Validation Loss: 0.0578, Accuracy: 0.9817\n",
      "Evaluating at step 820\n",
      "Validation Loss: 0.0899, Accuracy: 0.9717\n",
      "Evaluating at step 840\n",
      "Validation Loss: 0.0801, Accuracy: 0.9733\n",
      "Evaluating at step 860\n",
      "Validation Loss: 0.0748, Accuracy: 0.9633\n",
      "Evaluating at step 880\n",
      "Validation Loss: 0.0945, Accuracy: 0.9633\n",
      "Evaluating at step 900\n",
      "Validation Loss: 0.0698, Accuracy: 0.9717\n",
      "Training Loss: 0.1491\n",
      "====================\n",
      "Starting epoch 2/5\n",
      "====================\n",
      "Evaluating at step 0\n",
      "Validation Loss: 0.0965, Accuracy: 0.9650\n",
      "Evaluating at step 20\n",
      "Validation Loss: 0.0797, Accuracy: 0.9683\n",
      "Evaluating at step 40\n",
      "Validation Loss: 0.1013, Accuracy: 0.9650\n",
      "Evaluating at step 60\n",
      "Validation Loss: 0.1025, Accuracy: 0.9633\n",
      "Evaluating at step 80\n",
      "Validation Loss: 0.0611, Accuracy: 0.9717\n",
      "Evaluating at step 100\n",
      "Validation Loss: 0.0686, Accuracy: 0.9767\n",
      "Evaluating at step 120\n",
      "Validation Loss: 0.0529, Accuracy: 0.9783\n",
      "Evaluating at step 140\n",
      "Validation Loss: 0.0856, Accuracy: 0.9767\n",
      "Evaluating at step 160\n",
      "Validation Loss: 0.1048, Accuracy: 0.9633\n",
      "Evaluating at step 180\n",
      "Validation Loss: 0.0754, Accuracy: 0.9750\n",
      "Evaluating at step 200\n",
      "Validation Loss: 0.0556, Accuracy: 0.9783\n",
      "Evaluating at step 220\n",
      "Validation Loss: 0.0755, Accuracy: 0.9733\n",
      "Evaluating at step 240\n",
      "Validation Loss: 0.0653, Accuracy: 0.9767\n",
      "Evaluating at step 260\n",
      "Validation Loss: 0.0335, Accuracy: 0.9933\n",
      "Evaluating at step 280\n",
      "Validation Loss: 0.0419, Accuracy: 0.9933\n",
      "Evaluating at step 300\n",
      "Validation Loss: 0.0708, Accuracy: 0.9783\n",
      "Evaluating at step 320\n",
      "Validation Loss: 0.0487, Accuracy: 0.9783\n",
      "Evaluating at step 340\n",
      "Validation Loss: 0.0650, Accuracy: 0.9750\n",
      "Evaluating at step 360\n",
      "Validation Loss: 0.0640, Accuracy: 0.9717\n",
      "Evaluating at step 380\n",
      "Validation Loss: 0.0499, Accuracy: 0.9750\n",
      "Evaluating at step 400\n",
      "Validation Loss: 0.0521, Accuracy: 0.9833\n",
      "Evaluating at step 420\n",
      "Validation Loss: 0.0500, Accuracy: 0.9850\n",
      "Evaluating at step 440\n",
      "Validation Loss: 0.1207, Accuracy: 0.9467\n",
      "Evaluating at step 460\n",
      "Validation Loss: 0.0468, Accuracy: 0.9817\n",
      "Evaluating at step 480\n",
      "Validation Loss: 0.1349, Accuracy: 0.9600\n",
      "Evaluating at step 500\n",
      "Validation Loss: 0.0305, Accuracy: 0.9883\n",
      "Evaluating at step 520\n",
      "Validation Loss: 0.0374, Accuracy: 0.9867\n",
      "Evaluating at step 540\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<timed eval>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-27-0d8a1f362571>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(epochs)\u001B[0m\n\u001B[1;32m     27\u001B[0m                 \u001B[0mtrue_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mval_step\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdl_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 29\u001B[0;31m                     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimages\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     30\u001B[0m                     \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m                     \u001B[0mval_loss\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dev/python/covid-detector-model/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dev/python/covid-detector-model/venv/lib/python3.6/site-packages/torchvision/models/resnet.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    247\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    248\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 249\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    250\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    251\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dev/python/covid-detector-model/venv/lib/python3.6/site-packages/torchvision/models/resnet.py\u001B[0m in \u001B[0;36m_forward_impl\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    237\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 238\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    239\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer3\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    240\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer4\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dev/python/covid-detector-model/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dev/python/covid-detector-model/venv/lib/python3.6/site-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    137\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    138\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 139\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    140\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dev/python/covid-detector-model/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dev/python/covid-detector-model/venv/lib/python3.6/site-packages/torchvision/models/resnet.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     68\u001B[0m         \u001B[0midentity\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 70\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     71\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbn1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dev/python/covid-detector-model/venv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1051\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1052\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dev/python/covid-detector-model/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    442\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 443\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/dev/python/covid-detector-model/venv/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    438\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[1;32m    439\u001B[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[0;32m--> 440\u001B[0;31m                         self.padding, self.dilation, self.groups)\n\u001B[0m\u001B[1;32m    441\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    442\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = train_model(epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.97354   0.98660       189\n",
      "           1    0.98049   1.00000   0.99015       201\n",
      "           2    0.99526   1.00000   0.99762       210\n",
      "\n",
      "    accuracy                        0.99167       600\n",
      "   macro avg    0.99192   0.99118   0.99146       600\n",
      "weighted avg    0.99180   0.99167   0.99165       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x432 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(0.020421389756895798, tensor(0.9917))"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(show_plots=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model to be used by application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "torch.save(model, \"resnet50_V3.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load saved model for evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_TO_LOAD = \"resnet50_V3.pt\"\n",
    "\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(in_features=2048, out_features=3)\n",
    "model.load_state_dict(torch.load(MODEL_TO_LOAD))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}